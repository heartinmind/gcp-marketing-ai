"""
MarketingAI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê¸°ë³¸ ê¸°ëŠ¥ë“¤ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import sys
import os
import logging
from datetime import datetime
import hashlib

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from config.config import PROJECT_ID, DATASET_ID
from src.data_collection.web_scraper import WebScraper
from src.utils.bigquery_client import BigQueryClient
from src.analysis.basic_analyzer import BasicAnalyzer

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_web_scraper():
    """ì›¹ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ì›¹ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    scraper = WebScraper(delay=1)
    
    # í…ŒìŠ¤íŠ¸ìš© ê°„ë‹¨í•œ ì›¹ì‚¬ì´íŠ¸
    test_competitor = {
        "name": "test_site",
        "url": "https://httpbin.org",
        "target_pages": ["/html", "/json"]
    }
    
    try:
        results = scraper.scrape_competitor(test_competitor)
        logger.info(f"ìŠ¤í¬ë˜í•‘ ê²°ê³¼: {len(results)}ê°œ í˜ì´ì§€")
        
        for result in results:
            logger.info(f"- URL: {result['url']}")
            logger.info(f"- ì œëª©: {result['page_title'][:50]}...")
            logger.info(f"- ì½˜í…ì¸  ê¸¸ì´: {len(result['content'])}ì")
        
        return results
        
    except Exception as e:
        logger.error(f"ì›¹ ìŠ¤í¬ë˜í¼ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return []


def test_bigquery_client():
    """BigQuery í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸"""
    logger.info("=== BigQuery í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    bq_client = BigQueryClient(PROJECT_ID, DATASET_ID)
    
    try:
        # ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ í…ŒìŠ¤íŠ¸
        existing_data = bq_client.query_competitor_data(limit=5)
        logger.info(f"ê¸°ì¡´ ë°ì´í„° ì¡°íšŒ: {len(existing_data)}ê°œ ë ˆì½”ë“œ")
        
        return True
        
    except Exception as e:
        logger.error(f"BigQuery í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False


def test_basic_analyzer():
    """ê¸°ë³¸ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸"""
    logger.info("=== ê¸°ë³¸ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    analyzer = BasicAnalyzer()
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    test_data = [
        {
            'url': 'https://example.com/product1',
            'page_title': 'Amazing Product - Best Solution',
            'content': 'This is an amazing product that provides the best solution for your business needs. Our innovative technology helps companies grow.',
            'meta_description': 'Best product for business growth',
            'collected_at': '2024-01-01T10:00:00',
            'content_hash': 'hash1'
        },
        {
            'url': 'https://example.com/pricing',
            'page_title': 'Pricing Plans - Affordable Solutions',
            'content': 'Our pricing plans are designed to be affordable for businesses of all sizes. Choose the plan that fits your budget.',
            'meta_description': 'Affordable pricing plans',
            'collected_at': '2024-01-02T10:00:00',
            'content_hash': 'hash2'
        }
    ]
    
    try:
        # í‚¤ì›Œë“œ ë¶„ì„ í…ŒìŠ¤íŠ¸
        keyword_analysis = analyzer.analyze_keywords(test_data)
        logger.info(f"í‚¤ì›Œë“œ ë¶„ì„ ì™„ë£Œ: {keyword_analysis.get('unique_words', 0)}ê°œ ê³ ìœ  ë‹¨ì–´")
        
        # ì½˜í…ì¸  ë³€ê²½ ë¶„ì„ í…ŒìŠ¤íŠ¸
        change_analysis = analyzer.analyze_content_changes(test_data)
        logger.info(f"ì½˜í…ì¸  ë³€ê²½ ë¶„ì„ ì™„ë£Œ: {change_analysis.get('total_pages_monitored', 0)}ê°œ í˜ì´ì§€ ëª¨ë‹ˆí„°ë§")
        
        # ê²½ìŸì‚¬ ìš”ì•½ ë¶„ì„ í…ŒìŠ¤íŠ¸
        summary = analyzer.generate_competitor_summary('test_competitor', test_data)
        logger.info(f"ê²½ìŸì‚¬ ìš”ì•½ ë¶„ì„ ì™„ë£Œ: {summary.get('competitor_name', 'Unknown')}")
        
        return True
        
    except Exception as e:
        logger.error(f"ê¸°ë³¸ ë¶„ì„ê¸° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False


def test_integration():
    """í†µí•© í…ŒìŠ¤íŠ¸"""
    logger.info("=== í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        # 1. ì›¹ ìŠ¤í¬ë˜í•‘
        scraped_data = test_web_scraper()
        if not scraped_data:
            logger.warning("ì›¹ ìŠ¤í¬ë˜í•‘ ë°ì´í„°ê°€ ì—†ì–´ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return False
        
        # 2. BigQuery ì €ì¥
        bq_client = BigQueryClient(PROJECT_ID, DATASET_ID)
        success = bq_client.insert_competitor_data(scraped_data)
        
        if success:
            logger.info("BigQuery ì €ì¥ ì„±ê³µ")
        else:
            logger.error("BigQuery ì €ì¥ ì‹¤íŒ¨")
            return False
        
        # 3. ë°ì´í„° ë¶„ì„
        analyzer = BasicAnalyzer()
        keyword_analysis = analyzer.analyze_keywords(scraped_data)
        
        # 4. ë¶„ì„ ê²°ê³¼ ì €ì¥
        analysis_record = analyzer.create_analysis_record(
            competitor_name='test_site',
            analysis_type='keyword',
            results=keyword_analysis,
            summary=f"ì´ {keyword_analysis.get('unique_words', 0)}ê°œì˜ ê³ ìœ  í‚¤ì›Œë“œ ë°œê²¬"
        )
        
        analysis_success = bq_client.insert_analysis_results([analysis_record])
        
        if analysis_success:
            logger.info("ë¶„ì„ ê²°ê³¼ ì €ì¥ ì„±ê³µ")
            logger.info("=== í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ ===")
            return True
        else:
            logger.error("ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨")
            return False
        
    except Exception as e:
        logger.error(f"í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("MarketingAI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # ê°œë³„ ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸
    tests = [
        ("ì›¹ ìŠ¤í¬ë˜í¼", lambda: len(test_web_scraper()) > 0),
        ("BigQuery í´ë¼ì´ì–¸íŠ¸", test_bigquery_client),
        ("ê¸°ë³¸ ë¶„ì„ê¸°", test_basic_analyzer),
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            result = test_func()
            results[test_name] = result
            status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
            logger.info(f"{test_name}: {status}")
        except Exception as e:
            results[test_name] = False
            logger.error(f"{test_name}: âŒ ì‹¤íŒ¨ - {str(e)}")
    
    # í†µí•© í…ŒìŠ¤íŠ¸
    if all(results.values()):
        logger.info("ëª¨ë“  ê°œë³„ í…ŒìŠ¤íŠ¸ í†µê³¼. í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
        integration_result = test_integration()
        results["í†µí•© í…ŒìŠ¤íŠ¸"] = integration_result
        status = "âœ… ì„±ê³µ" if integration_result else "âŒ ì‹¤íŒ¨"
        logger.info(f"í†µí•© í…ŒìŠ¤íŠ¸: {status}")
    else:
        logger.warning("ì¼ë¶€ ê°œë³„ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ë¡œ í†µí•© í…ŒìŠ¤íŠ¸ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # ìµœì¢… ê²°ê³¼
    logger.info("\n=== í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ ===")
    for test_name, result in results.items():
        status = "âœ… ì„±ê³µ" if result else "âŒ ì‹¤íŒ¨"
        logger.info(f"{test_name}: {status}")
    
    success_rate = sum(results.values()) / len(results) * 100
    logger.info(f"ì „ì²´ ì„±ê³µë¥ : {success_rate:.1f}%")
    
    if success_rate == 100:
        logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µí–ˆìŠµë‹ˆë‹¤! ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•©ë‹ˆë‹¤.")
    else:
        logger.warning("âš ï¸ ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¬¸ì œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")


if __name__ == "__main__":
    main() 
